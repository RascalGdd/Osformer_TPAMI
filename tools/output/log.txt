[11/09 14:44:14] detectron2 INFO: Rank of current process: 0. World size: 1
[11/09 14:44:15] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.13 (default, Oct 21 2022, 23:50:54) [GCC 11.2.0]
numpy                   1.23.3
detectron2              0.6 @/home/pjl307/anaconda3/envs/osformer2/lib/python3.8/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/pjl307/anaconda3/envs/osformer2/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 Ti (arch=8.6)
Driver version          510.85.02
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.11.0 @/home/pjl307/anaconda3/envs/osformer2/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/09 14:44:15] detectron2 INFO: Command line arguments: Namespace(config_file='/home/pjl307/projects/OSFormerV2/configs/CIS_R50.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/media/pjl307/data/experiment/CIS/OSFormerv2/R50-bs2-5e-5-90k-adamw-temperature_3000-querychange/model_final.pth'], resume=False)
[11/09 14:44:15] detectron2 INFO: Contents of args.config_file=/home/pjl307/projects/OSFormerV2/configs/CIS_R50.yaml:
_BASE_: "Base-CIS.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  RESNETS:
    DEPTH: 50
SOLVER:
  OPTIMIZER: "ADAMW"
  BASE_LR: 0.00005
[11/09 14:44:15] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - my_data_test_coco_cod_style
  - my_data_test_coco_nc4k_style
  TRAIN:
  - my_data_train_coco_cod_style
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    CROP_INSTANCE: true
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  HFLIP_TRAIN: true
  MASK_FORMAT: bitmask
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    ANTI_ALIAS: false
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BASIS_MODULE:
    ANN_SET: coco
    COMMON_STRIDE: 8
    CONVS_DIM: 128
    IN_FEATURES:
    - p3
    - p4
    - p5
    LOSS_ON: false
    LOSS_WEIGHT: 0.3
    NAME: ProtoNet
    NORM: SyncBN
    NUM_BASES: 4
    NUM_CLASSES: 1
    NUM_CONVS: 3
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: OSFormer
  MOBILENET: false
  OSFormer:
    C2F_MASK: true
    CLS_THRESHOLD: 0.005
    DCIN_NORM: false
    DEC_LAYERS: 3
    DIM_FEEDFORWARD: 1024
    ENC_LAYERS: 6
    ENC_POINTS: 4
    FEAT_INSTANCE_STRIDES:
    - 8
    - 16
    - 32
    FEAT_SCALE_RANGES:
    - - 1
      - 192
    - - 96
      - 384
    - - 192
      - 2048
    FFN: std
    HIDDEN_DIM: 256
    INSTANCE_CHANNELS: 256
    INSTANCE_IN_CHANNELS: 256
    INSTANCE_IN_FEATURES:
    - res3
    - res4
    - res5
    INS_EDGE: false
    INS_FUSION: camin
    LOSS:
      CLASS_WEIGHT: 2.0
      DICE_WEIGHT: 3.0
      FOCAL_ALPHA: 0.25
      FOCAL_GAMMA: 2.0
      FOCAL_USE_SIGMOID: true
      FOCAL_WEIGHT: 1.0
      INS_EDGE_WEIGHT: 1.0
      ITEMS:
      - labels
      - masks
      - loss_sem
      MASK_DICE_WEIGHT: 2.0
      MASK_PIXEL_WEIGHT: 5.0
      NAME: SparseInstCriterion
      OBJECTNESS_WEIGHT: 1.0
      SEM_TYPE: dice
      SEM_WEIGHT: 1.0
    MASK_CHANNELS: 128
    MASK_IN_CHANNELS: 256
    MASK_IN_FEATURES:
    - res2
    - trans3
    - trans4
    - trans5
    MASK_THR: 0.5
    MASK_THRESHOLD: 0.45
    MATCHER:
      ALPHA: 0.8
      BETA: 0.2
      NAME: SparseInstMatcher
    MAX_DETECTIONS: 100
    MAX_PER_IMG: 100
    NHEAD: 8
    NMS_KERNEL: gaussian
    NMS_PRE: 500
    NMS_SIGMA: 2
    NMS_TYPE: matrix
    NOFPN: true
    NORM: GN
    NUMBER_FEATURE_LEVELS: 5
    NUM_CLASSES: 1
    NUM_GRIDS:
    - 36
    - 24
    - 16
    NUM_INSTANCE_CONVS: 4
    NUM_KERNELS: 256
    NUM_MASKS: 256
    PRIOR_PROB: 0.01
    QS:
      ENABLE: true
      INPUT: ENC
      NUM_MASKS: 20
      NUM_QUERIES: 300
      SHARE_HEAD: false
    RESIZE_INPUT_FACTOR: 1
    SCORE_THR: 0.1
    SEM_LOSS: true
    SIGMA: 0.2
    SINGLE_SEM: false
    TYPE_DCN: DCN
    UPDATE_THR: 0.05
    USE_COORD_CONV: true
    USE_DCN_IN_INSTANCE: false
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  PVTV2:
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
  RESNETS:
    DEFORM_INTERVAL: 1
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 1
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: /media/pjl307/data/experiment/CIS/OSFormerv2/R50-bs2-5e-5-90k-adamw-temperature_3000-querychange/model_final.pth
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 5.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 60000
  - 80000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/09 14:44:15] detectron2 INFO: Full config saved to ./output/config.yaml
[11/09 14:44:15] d2.utils.env INFO: Using a generated random seed 15156701
[11/09 14:44:17] d2.engine.defaults INFO: Model:
OSFormer(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (cate_head): CISTransformerHead(
    (trans_encoder): CISTransformerEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): TransformerEncoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): TransformerEncoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): TransformerEncoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (4): TransformerEncoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (5): TransformerEncoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (reference_points): Linear(in_features=256, out_features=2, bias=True)
    )
    (trans_decoder): CISTransformerDecoder(
      (decoder): TransformerDecoder(
        (layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): TransformerDecoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): TransformerDecoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (reference_points): Linear(in_features=256, out_features=2, bias=True)
    )
    (cate_pred): Linear(in_features=256, out_features=1, bias=True)
    (kernel_pred): Linear(in_features=256, out_features=256, bias=True)
    (score_pred): Linear(in_features=256, out_features=1, bias=True)
    (reduce_channel): Conv2d(256, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
    (qs_pred): Linear(in_features=256, out_features=256, bias=True)
    (position_encoding): PositionEmbeddingSine()
  )
  (mask_head): C2FMaskHead(
    (convs_all_levels): ModuleList(
      (0): Sequential(
        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
    )
    (convs_all_sums): ModuleList(
      (0): Sequential(
        (conv0): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
      )
      (1): Sequential(
        (conv1): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)
      )
      (2): Sequential(
        (conv2): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
        (upsample2): Upsample(scale_factor=2.0, mode=bilinear)
      )
      (3): Sequential(
        (conv3): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
        (upsample3): Upsample(scale_factor=2.0, mode=bilinear)
      )
    )
    (conv_pred): Sequential(
      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
    (edge_all_levels): ModuleList(
      (0): ReverseEdgeSupervision(
        (edge_pred): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
      )
      (1): ReverseEdgeSupervision(
        (edge_pred): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
      )
      (2): ReverseEdgeSupervision(
        (edge_pred): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
      )
    )
  )
  (res_modules): ModuleList(
    (0): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
    (1): Sequential(
      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
    (2): Sequential(
      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
    (3): Sequential(
      (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
  )
  (dcin): DCIN(
    (affine_scale): Linear(in_features=256, out_features=256, bias=True)
    (affine_bias): Linear(in_features=256, out_features=1, bias=True)
  )
  (criterion): SparseInstCriterion(
    (matcher): SparseInstMatcher()
  )
)
[11/09 14:44:17] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/pjl307/data/experiment/CIS/OSFormerv2/R50-bs2-5e-5-90k-adamw-temperature_3000-querychange/model_final.pth ...
[11/09 14:44:18] d2.data.datasets.coco INFO: Loaded 2026 images in COCO format from /media/pjl307/data/experiment/datasets/CIS/annotations/test2026.json
[11/09 14:44:18] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| foreground | 2365         |
|            |              |[0m
[11/09 14:44:18] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/09 14:44:18] d2.data.common INFO: Serializing 2026 elements to byte tensors and concatenating them all ...
[11/09 14:44:18] d2.data.common INFO: Serialized dataset takes 5.94 MiB
[11/09 14:44:18] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/09 14:44:18] d2.evaluation.evaluator INFO: Start inference on 2026 batches
[11/09 14:45:30] detectron2 INFO: Rank of current process: 0. World size: 1
[11/09 14:45:31] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.13 (default, Oct 21 2022, 23:50:54) [GCC 11.2.0]
numpy                   1.23.3
detectron2              0.6 @/home/pjl307/anaconda3/envs/osformer2/lib/python3.8/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/pjl307/anaconda3/envs/osformer2/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 Ti (arch=8.6)
Driver version          510.85.02
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.11.0 @/home/pjl307/anaconda3/envs/osformer2/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/09 14:45:31] detectron2 INFO: Command line arguments: Namespace(config_file='/home/pjl307/projects/OSFormerV2/configs/CIS_R50.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/media/pjl307/data/experiment/CIS/OSFormerv2/R50-bs2-5e-5-90k-adamw-temperature_3000-querychange/model_final.pth'], resume=False)
[11/09 14:45:31] detectron2 INFO: Contents of args.config_file=/home/pjl307/projects/OSFormerV2/configs/CIS_R50.yaml:
_BASE_: "Base-CIS.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  RESNETS:
    DEPTH: 50
SOLVER:
  OPTIMIZER: "ADAMW"
  BASE_LR: 0.00005
[11/09 14:45:31] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - my_data_test_coco_cod_style
  - my_data_test_coco_nc4k_style
  TRAIN:
  - my_data_train_coco_cod_style
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    CROP_INSTANCE: true
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  HFLIP_TRAIN: true
  MASK_FORMAT: bitmask
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    ANTI_ALIAS: false
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BASIS_MODULE:
    ANN_SET: coco
    COMMON_STRIDE: 8
    CONVS_DIM: 128
    IN_FEATURES:
    - p3
    - p4
    - p5
    LOSS_ON: false
    LOSS_WEIGHT: 0.3
    NAME: ProtoNet
    NORM: SyncBN
    NUM_BASES: 4
    NUM_CLASSES: 1
    NUM_CONVS: 3
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: OSFormer
  MOBILENET: false
  OSFormer:
    C2F_MASK: true
    CLS_THRESHOLD: 0.005
    DCIN_NORM: false
    DEC_LAYERS: 3
    DIM_FEEDFORWARD: 1024
    ENC_LAYERS: 6
    ENC_POINTS: 4
    FEAT_INSTANCE_STRIDES:
    - 8
    - 16
    - 32
    FEAT_SCALE_RANGES:
    - - 1
      - 192
    - - 96
      - 384
    - - 192
      - 2048
    FFN: std
    HIDDEN_DIM: 256
    INSTANCE_CHANNELS: 256
    INSTANCE_IN_CHANNELS: 256
    INSTANCE_IN_FEATURES:
    - res3
    - res4
    - res5
    INS_EDGE: false
    INS_FUSION: camin
    LOSS:
      CLASS_WEIGHT: 2.0
      DICE_WEIGHT: 3.0
      FOCAL_ALPHA: 0.25
      FOCAL_GAMMA: 2.0
      FOCAL_USE_SIGMOID: true
      FOCAL_WEIGHT: 1.0
      INS_EDGE_WEIGHT: 1.0
      ITEMS:
      - labels
      - masks
      - loss_sem
      MASK_DICE_WEIGHT: 2.0
      MASK_PIXEL_WEIGHT: 5.0
      NAME: SparseInstCriterion
      OBJECTNESS_WEIGHT: 1.0
      SEM_TYPE: dice
      SEM_WEIGHT: 1.0
    MASK_CHANNELS: 128
    MASK_IN_CHANNELS: 256
    MASK_IN_FEATURES:
    - res2
    - trans3
    - trans4
    - trans5
    MASK_THR: 0.5
    MASK_THRESHOLD: 0.45
    MATCHER:
      ALPHA: 0.8
      BETA: 0.2
      NAME: SparseInstMatcher
    MAX_DETECTIONS: 100
    MAX_PER_IMG: 100
    NHEAD: 8
    NMS_KERNEL: gaussian
    NMS_PRE: 500
    NMS_SIGMA: 2
    NMS_TYPE: matrix
    NOFPN: true
    NORM: GN
    NUMBER_FEATURE_LEVELS: 5
    NUM_CLASSES: 1
    NUM_GRIDS:
    - 36
    - 24
    - 16
    NUM_INSTANCE_CONVS: 4
    NUM_KERNELS: 256
    NUM_MASKS: 256
    PRIOR_PROB: 0.01
    QS:
      ENABLE: true
      INPUT: ENC
      NUM_MASKS: 20
      NUM_QUERIES: 300
      SHARE_HEAD: false
    RESIZE_INPUT_FACTOR: 1
    SCORE_THR: 0.1
    SEM_LOSS: true
    SIGMA: 0.2
    SINGLE_SEM: false
    TYPE_DCN: DCN
    UPDATE_THR: 0.05
    USE_COORD_CONV: true
    USE_DCN_IN_INSTANCE: false
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  PVTV2:
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
  RESNETS:
    DEFORM_INTERVAL: 1
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 1
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: /media/pjl307/data/experiment/CIS/OSFormerv2/R50-bs2-5e-5-90k-adamw-temperature_3000-querychange/model_final.pth
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 5.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 60000
  - 80000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/09 14:45:31] detectron2 INFO: Full config saved to ./output/config.yaml
[11/09 14:45:31] d2.utils.env INFO: Using a generated random seed 31302275
[11/09 14:45:34] d2.engine.defaults INFO: Model:
OSFormer(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (cate_head): CISTransformerHead(
    (trans_encoder): CISTransformerEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): TransformerEncoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): TransformerEncoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): TransformerEncoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (4): TransformerEncoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (5): TransformerEncoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (reference_points): Linear(in_features=256, out_features=2, bias=True)
    )
    (trans_decoder): CISTransformerDecoder(
      (decoder): TransformerDecoder(
        (layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): TransformerDecoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): TransformerDecoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (reference_points): Linear(in_features=256, out_features=2, bias=True)
    )
    (cate_pred): Linear(in_features=256, out_features=1, bias=True)
    (kernel_pred): Linear(in_features=256, out_features=256, bias=True)
    (score_pred): Linear(in_features=256, out_features=1, bias=True)
    (reduce_channel): Conv2d(256, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
    (qs_pred): Linear(in_features=256, out_features=256, bias=True)
    (position_encoding): PositionEmbeddingSine()
  )
  (mask_head): C2FMaskHead(
    (convs_all_levels): ModuleList(
      (0): Sequential(
        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
    )
    (convs_all_sums): ModuleList(
      (0): Sequential(
        (conv0): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
      )
      (1): Sequential(
        (conv1): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)
      )
      (2): Sequential(
        (conv2): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
        (upsample2): Upsample(scale_factor=2.0, mode=bilinear)
      )
      (3): Sequential(
        (conv3): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
        (upsample3): Upsample(scale_factor=2.0, mode=bilinear)
      )
    )
    (conv_pred): Sequential(
      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
    (edge_all_levels): ModuleList(
      (0): ReverseEdgeSupervision(
        (edge_pred): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
      )
      (1): ReverseEdgeSupervision(
        (edge_pred): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
      )
      (2): ReverseEdgeSupervision(
        (edge_pred): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
      )
    )
  )
  (res_modules): ModuleList(
    (0): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
    (1): Sequential(
      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
    (2): Sequential(
      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
    (3): Sequential(
      (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
  )
  (dcin): DCIN(
    (affine_scale): Linear(in_features=256, out_features=256, bias=True)
    (affine_bias): Linear(in_features=256, out_features=1, bias=True)
  )
  (criterion): SparseInstCriterion(
    (matcher): SparseInstMatcher()
  )
)
[11/09 14:45:34] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/pjl307/data/experiment/CIS/OSFormerv2/R50-bs2-5e-5-90k-adamw-temperature_3000-querychange/model_final.pth ...
[11/09 14:45:34] d2.data.datasets.coco INFO: Loaded 2026 images in COCO format from /media/pjl307/data/experiment/datasets/CIS/annotations/test2026.json
[11/09 14:45:34] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| foreground | 2365         |
|            |              |[0m
[11/09 14:45:34] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/09 14:45:34] d2.data.common INFO: Serializing 2026 elements to byte tensors and concatenating them all ...
[11/09 14:45:34] d2.data.common INFO: Serialized dataset takes 5.94 MiB
[11/09 14:45:34] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/09 14:45:34] d2.evaluation.evaluator INFO: Start inference on 2026 batches
[11/09 14:46:28] detectron2 INFO: Rank of current process: 0. World size: 1
[11/09 14:46:28] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.13 (default, Oct 21 2022, 23:50:54) [GCC 11.2.0]
numpy                   1.23.3
detectron2              0.6 @/home/pjl307/anaconda3/envs/osformer2/lib/python3.8/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/pjl307/anaconda3/envs/osformer2/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 Ti (arch=8.6)
Driver version          510.85.02
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.11.0 @/home/pjl307/anaconda3/envs/osformer2/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  -------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/09 14:46:28] detectron2 INFO: Command line arguments: Namespace(config_file='/home/pjl307/projects/OSFormerV2/configs/CIS_R50.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/media/pjl307/data/experiment/CIS/OSFormerv2/R50-bs2-5e-5-90k-adamw-temperature_3000-querychange/model_final.pth'], resume=False)
[11/09 14:46:28] detectron2 INFO: Contents of args.config_file=/home/pjl307/projects/OSFormerV2/configs/CIS_R50.yaml:
_BASE_: "Base-CIS.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  RESNETS:
    DEPTH: 50
SOLVER:
  OPTIMIZER: "ADAMW"
  BASE_LR: 0.00005
[11/09 14:46:28] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - my_data_test_coco_cod_style
  - my_data_test_coco_nc4k_style
  TRAIN:
  - my_data_train_coco_cod_style
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    CROP_INSTANCE: true
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  HFLIP_TRAIN: true
  MASK_FORMAT: bitmask
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    ANTI_ALIAS: false
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  BASIS_MODULE:
    ANN_SET: coco
    COMMON_STRIDE: 8
    CONVS_DIM: 128
    IN_FEATURES:
    - p3
    - p4
    - p5
    LOSS_ON: false
    LOSS_WEIGHT: 0.3
    NAME: ProtoNet
    NORM: SyncBN
    NUM_BASES: 4
    NUM_CLASSES: 1
    NUM_CONVS: 3
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: OSFormer
  MOBILENET: false
  OSFormer:
    C2F_MASK: true
    CLS_THRESHOLD: 0.005
    DCIN_NORM: false
    DEC_LAYERS: 3
    DIM_FEEDFORWARD: 1024
    ENC_LAYERS: 6
    ENC_POINTS: 4
    FEAT_INSTANCE_STRIDES:
    - 8
    - 16
    - 32
    FEAT_SCALE_RANGES:
    - - 1
      - 192
    - - 96
      - 384
    - - 192
      - 2048
    FFN: std
    HIDDEN_DIM: 256
    INSTANCE_CHANNELS: 256
    INSTANCE_IN_CHANNELS: 256
    INSTANCE_IN_FEATURES:
    - res3
    - res4
    - res5
    INS_EDGE: false
    INS_FUSION: camin
    LOSS:
      CLASS_WEIGHT: 2.0
      DICE_WEIGHT: 3.0
      FOCAL_ALPHA: 0.25
      FOCAL_GAMMA: 2.0
      FOCAL_USE_SIGMOID: true
      FOCAL_WEIGHT: 1.0
      INS_EDGE_WEIGHT: 1.0
      ITEMS:
      - labels
      - masks
      - loss_sem
      MASK_DICE_WEIGHT: 2.0
      MASK_PIXEL_WEIGHT: 5.0
      NAME: SparseInstCriterion
      OBJECTNESS_WEIGHT: 1.0
      SEM_TYPE: dice
      SEM_WEIGHT: 1.0
    MASK_CHANNELS: 128
    MASK_IN_CHANNELS: 256
    MASK_IN_FEATURES:
    - res2
    - trans3
    - trans4
    - trans5
    MASK_THR: 0.5
    MASK_THRESHOLD: 0.45
    MATCHER:
      ALPHA: 0.8
      BETA: 0.2
      NAME: SparseInstMatcher
    MAX_DETECTIONS: 100
    MAX_PER_IMG: 100
    NHEAD: 8
    NMS_KERNEL: gaussian
    NMS_PRE: 500
    NMS_SIGMA: 2
    NMS_TYPE: matrix
    NOFPN: true
    NORM: GN
    NUMBER_FEATURE_LEVELS: 5
    NUM_CLASSES: 1
    NUM_GRIDS:
    - 36
    - 24
    - 16
    NUM_INSTANCE_CONVS: 4
    NUM_KERNELS: 256
    NUM_MASKS: 256
    PRIOR_PROB: 0.01
    QS:
      ENABLE: true
      INPUT: ENC
      NUM_MASKS: 20
      NUM_QUERIES: 300
      SHARE_HEAD: false
    RESIZE_INPUT_FACTOR: 1
    SCORE_THR: 0.1
    SEM_LOSS: true
    SIGMA: 0.2
    SINGLE_SEM: false
    TYPE_DCN: DCN
    UPDATE_THR: 0.05
    USE_COORD_CONV: true
    USE_DCN_IN_INSTANCE: false
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  PVTV2:
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
  RESNETS:
    DEFORM_INTERVAL: 1
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 1
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: /media/pjl307/data/experiment/CIS/OSFormerv2/R50-bs2-5e-5-90k-adamw-temperature_3000-querychange/model_final.pth
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 5.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 60000
  - 80000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/09 14:46:29] detectron2 INFO: Full config saved to ./output/config.yaml
[11/09 14:46:29] d2.utils.env INFO: Using a generated random seed 29135056
[11/09 14:46:31] d2.engine.defaults INFO: Model:
OSFormer(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (cate_head): CISTransformerHead(
    (trans_encoder): CISTransformerEncoder(
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): TransformerEncoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): TransformerEncoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): TransformerEncoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (4): TransformerEncoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (5): TransformerEncoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (reference_points): Linear(in_features=256, out_features=2, bias=True)
    )
    (trans_decoder): CISTransformerDecoder(
      (decoder): TransformerDecoder(
        (layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): TransformerDecoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): TransformerDecoderLayer(
            (self_attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
              (attention_weights): Linear(in_features=256, out_features=96, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (ffn): StdFeedForwardNetwork(
              (ffn): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU()
                (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              )
              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (reference_points): Linear(in_features=256, out_features=2, bias=True)
    )
    (cate_pred): Linear(in_features=256, out_features=1, bias=True)
    (kernel_pred): Linear(in_features=256, out_features=256, bias=True)
    (score_pred): Linear(in_features=256, out_features=1, bias=True)
    (reduce_channel): Conv2d(256, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
    (qs_pred): Linear(in_features=256, out_features=256, bias=True)
    (position_encoding): PositionEmbeddingSine()
  )
  (mask_head): C2FMaskHead(
    (convs_all_levels): ModuleList(
      (0): Sequential(
        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (1): Sequential(
        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (2): Sequential(
        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
    )
    (convs_all_sums): ModuleList(
      (0): Sequential(
        (conv0): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
      )
      (1): Sequential(
        (conv1): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)
      )
      (2): Sequential(
        (conv2): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
        (upsample2): Upsample(scale_factor=2.0, mode=bilinear)
      )
      (3): Sequential(
        (conv3): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
        (upsample3): Upsample(scale_factor=2.0, mode=bilinear)
      )
    )
    (conv_pred): Sequential(
      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
    (edge_all_levels): ModuleList(
      (0): ReverseEdgeSupervision(
        (edge_pred): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
      )
      (1): ReverseEdgeSupervision(
        (edge_pred): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
      )
      (2): ReverseEdgeSupervision(
        (edge_pred): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
      )
    )
  )
  (res_modules): ModuleList(
    (0): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
    (1): Sequential(
      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
    (2): Sequential(
      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
    (3): Sequential(
      (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): GroupNorm(32, 256, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
    )
  )
  (dcin): DCIN(
    (affine_scale): Linear(in_features=256, out_features=256, bias=True)
    (affine_bias): Linear(in_features=256, out_features=1, bias=True)
  )
  (criterion): SparseInstCriterion(
    (matcher): SparseInstMatcher()
  )
)
[11/09 14:46:31] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/pjl307/data/experiment/CIS/OSFormerv2/R50-bs2-5e-5-90k-adamw-temperature_3000-querychange/model_final.pth ...
[11/09 14:46:32] d2.data.datasets.coco INFO: Loaded 2026 images in COCO format from /media/pjl307/data/experiment/datasets/CIS/annotations/test2026.json
[11/09 14:46:32] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| foreground | 2365         |
|            |              |[0m
[11/09 14:46:32] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/09 14:46:32] d2.data.common INFO: Serializing 2026 elements to byte tensors and concatenating them all ...
[11/09 14:46:32] d2.data.common INFO: Serialized dataset takes 5.94 MiB
[11/09 14:46:32] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/09 14:46:32] d2.evaluation.evaluator INFO: Start inference on 2026 batches
[11/09 14:46:35] d2.evaluation.evaluator INFO: Inference done 11/2026. Dataloading: 0.0005 s/iter. Inference: 0.1008 s/iter. Eval: 0.1087 s/iter. Total: 0.2099 s/iter. ETA=0:07:03
[11/09 14:46:40] d2.evaluation.evaluator INFO: Inference done 39/2026. Dataloading: 0.0007 s/iter. Inference: 0.0751 s/iter. Eval: 0.1097 s/iter. Total: 0.1856 s/iter. ETA=0:06:08
[11/09 14:46:45] d2.evaluation.evaluator INFO: Inference done 68/2026. Dataloading: 0.0007 s/iter. Inference: 0.0700 s/iter. Eval: 0.1096 s/iter. Total: 0.1804 s/iter. ETA=0:05:53
[11/09 14:46:50] d2.evaluation.evaluator INFO: Inference done 102/2026. Dataloading: 0.0007 s/iter. Inference: 0.0656 s/iter. Eval: 0.1029 s/iter. Total: 0.1693 s/iter. ETA=0:05:25
[11/09 14:46:55] d2.evaluation.evaluator INFO: Inference done 133/2026. Dataloading: 0.0007 s/iter. Inference: 0.0622 s/iter. Eval: 0.1045 s/iter. Total: 0.1674 s/iter. ETA=0:05:16
[11/09 14:47:01] d2.evaluation.evaluator INFO: Inference done 165/2026. Dataloading: 0.0007 s/iter. Inference: 0.0590 s/iter. Eval: 0.1060 s/iter. Total: 0.1657 s/iter. ETA=0:05:08
[11/09 14:47:06] d2.evaluation.evaluator INFO: Inference done 195/2026. Dataloading: 0.0007 s/iter. Inference: 0.0575 s/iter. Eval: 0.1084 s/iter. Total: 0.1666 s/iter. ETA=0:05:05
[11/09 14:47:11] d2.evaluation.evaluator INFO: Inference done 227/2026. Dataloading: 0.0007 s/iter. Inference: 0.0557 s/iter. Eval: 0.1090 s/iter. Total: 0.1655 s/iter. ETA=0:04:57
[11/09 14:47:16] d2.evaluation.evaluator INFO: Inference done 258/2026. Dataloading: 0.0007 s/iter. Inference: 0.0553 s/iter. Eval: 0.1095 s/iter. Total: 0.1656 s/iter. ETA=0:04:52
[11/09 14:47:21] d2.evaluation.evaluator INFO: Inference done 291/2026. Dataloading: 0.0007 s/iter. Inference: 0.0543 s/iter. Eval: 0.1091 s/iter. Total: 0.1642 s/iter. ETA=0:04:44
[11/09 14:47:26] d2.evaluation.evaluator INFO: Inference done 323/2026. Dataloading: 0.0008 s/iter. Inference: 0.0538 s/iter. Eval: 0.1092 s/iter. Total: 0.1638 s/iter. ETA=0:04:38
[11/09 14:47:31] d2.evaluation.evaluator INFO: Inference done 353/2026. Dataloading: 0.0008 s/iter. Inference: 0.0533 s/iter. Eval: 0.1104 s/iter. Total: 0.1645 s/iter. ETA=0:04:35
[11/09 14:47:36] d2.evaluation.evaluator INFO: Inference done 384/2026. Dataloading: 0.0008 s/iter. Inference: 0.0533 s/iter. Eval: 0.1102 s/iter. Total: 0.1643 s/iter. ETA=0:04:29
[11/09 14:47:41] d2.evaluation.evaluator INFO: Inference done 418/2026. Dataloading: 0.0008 s/iter. Inference: 0.0527 s/iter. Eval: 0.1097 s/iter. Total: 0.1632 s/iter. ETA=0:04:22
[11/09 14:47:47] d2.evaluation.evaluator INFO: Inference done 449/2026. Dataloading: 0.0008 s/iter. Inference: 0.0522 s/iter. Eval: 0.1103 s/iter. Total: 0.1633 s/iter. ETA=0:04:17
[11/09 14:47:52] d2.evaluation.evaluator INFO: Inference done 481/2026. Dataloading: 0.0008 s/iter. Inference: 0.0517 s/iter. Eval: 0.1104 s/iter. Total: 0.1630 s/iter. ETA=0:04:11
[11/09 14:47:57] d2.evaluation.evaluator INFO: Inference done 512/2026. Dataloading: 0.0008 s/iter. Inference: 0.0514 s/iter. Eval: 0.1107 s/iter. Total: 0.1629 s/iter. ETA=0:04:06
[11/09 14:48:02] d2.evaluation.evaluator INFO: Inference done 542/2026. Dataloading: 0.0008 s/iter. Inference: 0.0510 s/iter. Eval: 0.1114 s/iter. Total: 0.1632 s/iter. ETA=0:04:02
[11/09 14:48:07] d2.evaluation.evaluator INFO: Inference done 576/2026. Dataloading: 0.0008 s/iter. Inference: 0.0509 s/iter. Eval: 0.1109 s/iter. Total: 0.1626 s/iter. ETA=0:03:55
[11/09 14:48:12] d2.evaluation.evaluator INFO: Inference done 607/2026. Dataloading: 0.0008 s/iter. Inference: 0.0507 s/iter. Eval: 0.1110 s/iter. Total: 0.1625 s/iter. ETA=0:03:50
[11/09 14:48:17] d2.evaluation.evaluator INFO: Inference done 640/2026. Dataloading: 0.0008 s/iter. Inference: 0.0505 s/iter. Eval: 0.1107 s/iter. Total: 0.1620 s/iter. ETA=0:03:44
[11/09 14:48:22] d2.evaluation.evaluator INFO: Inference done 673/2026. Dataloading: 0.0008 s/iter. Inference: 0.0503 s/iter. Eval: 0.1106 s/iter. Total: 0.1616 s/iter. ETA=0:03:38
[11/09 14:48:27] d2.evaluation.evaluator INFO: Inference done 706/2026. Dataloading: 0.0008 s/iter. Inference: 0.0501 s/iter. Eval: 0.1104 s/iter. Total: 0.1613 s/iter. ETA=0:03:32
[11/09 14:48:33] d2.evaluation.evaluator INFO: Inference done 721/2026. Dataloading: 0.0008 s/iter. Inference: 0.0500 s/iter. Eval: 0.1149 s/iter. Total: 0.1657 s/iter. ETA=0:03:36
[11/09 14:48:38] d2.evaluation.evaluator INFO: Inference done 739/2026. Dataloading: 0.0008 s/iter. Inference: 0.0499 s/iter. Eval: 0.1178 s/iter. Total: 0.1685 s/iter. ETA=0:03:36
[11/09 14:48:43] d2.evaluation.evaluator INFO: Inference done 774/2026. Dataloading: 0.0008 s/iter. Inference: 0.0497 s/iter. Eval: 0.1170 s/iter. Total: 0.1675 s/iter. ETA=0:03:29
[11/09 14:48:48] d2.evaluation.evaluator INFO: Inference done 804/2026. Dataloading: 0.0008 s/iter. Inference: 0.0495 s/iter. Eval: 0.1175 s/iter. Total: 0.1677 s/iter. ETA=0:03:24
[11/09 14:48:53] d2.evaluation.evaluator INFO: Inference done 835/2026. Dataloading: 0.0008 s/iter. Inference: 0.0493 s/iter. Eval: 0.1176 s/iter. Total: 0.1677 s/iter. ETA=0:03:19
[11/09 14:48:58] d2.evaluation.evaluator INFO: Inference done 865/2026. Dataloading: 0.0008 s/iter. Inference: 0.0492 s/iter. Eval: 0.1177 s/iter. Total: 0.1677 s/iter. ETA=0:03:14
[11/09 14:49:03] d2.evaluation.evaluator INFO: Inference done 897/2026. Dataloading: 0.0008 s/iter. Inference: 0.0491 s/iter. Eval: 0.1174 s/iter. Total: 0.1673 s/iter. ETA=0:03:08
[11/09 14:49:08] d2.evaluation.evaluator INFO: Inference done 931/2026. Dataloading: 0.0008 s/iter. Inference: 0.0490 s/iter. Eval: 0.1170 s/iter. Total: 0.1667 s/iter. ETA=0:03:02
[11/09 14:49:14] d2.evaluation.evaluator INFO: Inference done 963/2026. Dataloading: 0.0008 s/iter. Inference: 0.0489 s/iter. Eval: 0.1168 s/iter. Total: 0.1665 s/iter. ETA=0:02:56
[11/09 14:49:19] d2.evaluation.evaluator INFO: Inference done 994/2026. Dataloading: 0.0008 s/iter. Inference: 0.0488 s/iter. Eval: 0.1168 s/iter. Total: 0.1664 s/iter. ETA=0:02:51
[11/09 14:49:24] d2.evaluation.evaluator INFO: Inference done 1025/2026. Dataloading: 0.0008 s/iter. Inference: 0.0487 s/iter. Eval: 0.1169 s/iter. Total: 0.1663 s/iter. ETA=0:02:46
[11/09 14:49:29] d2.evaluation.evaluator INFO: Inference done 1057/2026. Dataloading: 0.0008 s/iter. Inference: 0.0486 s/iter. Eval: 0.1166 s/iter. Total: 0.1660 s/iter. ETA=0:02:40
[11/09 14:49:34] d2.evaluation.evaluator INFO: Inference done 1090/2026. Dataloading: 0.0008 s/iter. Inference: 0.0485 s/iter. Eval: 0.1164 s/iter. Total: 0.1656 s/iter. ETA=0:02:35
[11/09 14:49:39] d2.evaluation.evaluator INFO: Inference done 1126/2026. Dataloading: 0.0008 s/iter. Inference: 0.0484 s/iter. Eval: 0.1157 s/iter. Total: 0.1649 s/iter. ETA=0:02:28
[11/09 14:49:44] d2.evaluation.evaluator INFO: Inference done 1157/2026. Dataloading: 0.0008 s/iter. Inference: 0.0483 s/iter. Eval: 0.1158 s/iter. Total: 0.1649 s/iter. ETA=0:02:23
[11/09 14:49:49] d2.evaluation.evaluator INFO: Inference done 1189/2026. Dataloading: 0.0008 s/iter. Inference: 0.0482 s/iter. Eval: 0.1157 s/iter. Total: 0.1647 s/iter. ETA=0:02:17
[11/09 14:49:54] d2.evaluation.evaluator INFO: Inference done 1219/2026. Dataloading: 0.0008 s/iter. Inference: 0.0482 s/iter. Eval: 0.1159 s/iter. Total: 0.1649 s/iter. ETA=0:02:13
[11/09 14:49:59] d2.evaluation.evaluator INFO: Inference done 1252/2026. Dataloading: 0.0008 s/iter. Inference: 0.0481 s/iter. Eval: 0.1157 s/iter. Total: 0.1646 s/iter. ETA=0:02:07
[11/09 14:50:04] d2.evaluation.evaluator INFO: Inference done 1284/2026. Dataloading: 0.0008 s/iter. Inference: 0.0481 s/iter. Eval: 0.1157 s/iter. Total: 0.1645 s/iter. ETA=0:02:02
[11/09 14:50:10] d2.evaluation.evaluator INFO: Inference done 1318/2026. Dataloading: 0.0008 s/iter. Inference: 0.0480 s/iter. Eval: 0.1153 s/iter. Total: 0.1641 s/iter. ETA=0:01:56
[11/09 14:50:15] d2.evaluation.evaluator INFO: Inference done 1350/2026. Dataloading: 0.0008 s/iter. Inference: 0.0480 s/iter. Eval: 0.1153 s/iter. Total: 0.1640 s/iter. ETA=0:01:50
[11/09 14:50:20] d2.evaluation.evaluator INFO: Inference done 1381/2026. Dataloading: 0.0008 s/iter. Inference: 0.0479 s/iter. Eval: 0.1153 s/iter. Total: 0.1640 s/iter. ETA=0:01:45
[11/09 14:50:25] d2.evaluation.evaluator INFO: Inference done 1412/2026. Dataloading: 0.0008 s/iter. Inference: 0.0478 s/iter. Eval: 0.1154 s/iter. Total: 0.1640 s/iter. ETA=0:01:40
[11/09 14:50:30] d2.evaluation.evaluator INFO: Inference done 1444/2026. Dataloading: 0.0008 s/iter. Inference: 0.0478 s/iter. Eval: 0.1153 s/iter. Total: 0.1639 s/iter. ETA=0:01:35
[11/09 14:50:35] d2.evaluation.evaluator INFO: Inference done 1477/2026. Dataloading: 0.0008 s/iter. Inference: 0.0477 s/iter. Eval: 0.1152 s/iter. Total: 0.1637 s/iter. ETA=0:01:29
[11/09 14:50:40] d2.evaluation.evaluator INFO: Inference done 1510/2026. Dataloading: 0.0008 s/iter. Inference: 0.0477 s/iter. Eval: 0.1150 s/iter. Total: 0.1635 s/iter. ETA=0:01:24
[11/09 14:50:45] d2.evaluation.evaluator INFO: Inference done 1540/2026. Dataloading: 0.0008 s/iter. Inference: 0.0477 s/iter. Eval: 0.1151 s/iter. Total: 0.1636 s/iter. ETA=0:01:19
[11/09 14:50:50] d2.evaluation.evaluator INFO: Inference done 1573/2026. Dataloading: 0.0008 s/iter. Inference: 0.0476 s/iter. Eval: 0.1150 s/iter. Total: 0.1634 s/iter. ETA=0:01:14
[11/09 14:50:55] d2.evaluation.evaluator INFO: Inference done 1607/2026. Dataloading: 0.0008 s/iter. Inference: 0.0476 s/iter. Eval: 0.1147 s/iter. Total: 0.1631 s/iter. ETA=0:01:08
[11/09 14:51:00] d2.evaluation.evaluator INFO: Inference done 1640/2026. Dataloading: 0.0008 s/iter. Inference: 0.0475 s/iter. Eval: 0.1146 s/iter. Total: 0.1629 s/iter. ETA=0:01:02
[11/09 14:51:05] d2.evaluation.evaluator INFO: Inference done 1672/2026. Dataloading: 0.0008 s/iter. Inference: 0.0475 s/iter. Eval: 0.1145 s/iter. Total: 0.1628 s/iter. ETA=0:00:57
[11/09 14:51:11] d2.evaluation.evaluator INFO: Inference done 1704/2026. Dataloading: 0.0008 s/iter. Inference: 0.0475 s/iter. Eval: 0.1145 s/iter. Total: 0.1627 s/iter. ETA=0:00:52
[11/09 14:51:16] d2.evaluation.evaluator INFO: Inference done 1735/2026. Dataloading: 0.0008 s/iter. Inference: 0.0474 s/iter. Eval: 0.1145 s/iter. Total: 0.1627 s/iter. ETA=0:00:47
[11/09 14:51:21] d2.evaluation.evaluator INFO: Inference done 1768/2026. Dataloading: 0.0008 s/iter. Inference: 0.0474 s/iter. Eval: 0.1144 s/iter. Total: 0.1625 s/iter. ETA=0:00:41
[11/09 14:51:26] d2.evaluation.evaluator INFO: Inference done 1800/2026. Dataloading: 0.0008 s/iter. Inference: 0.0474 s/iter. Eval: 0.1143 s/iter. Total: 0.1625 s/iter. ETA=0:00:36
[11/09 14:51:31] d2.evaluation.evaluator INFO: Inference done 1830/2026. Dataloading: 0.0008 s/iter. Inference: 0.0473 s/iter. Eval: 0.1146 s/iter. Total: 0.1627 s/iter. ETA=0:00:31
[11/09 14:51:36] d2.evaluation.evaluator INFO: Inference done 1863/2026. Dataloading: 0.0008 s/iter. Inference: 0.0473 s/iter. Eval: 0.1144 s/iter. Total: 0.1625 s/iter. ETA=0:00:26
[11/09 14:51:41] d2.evaluation.evaluator INFO: Inference done 1896/2026. Dataloading: 0.0008 s/iter. Inference: 0.0473 s/iter. Eval: 0.1143 s/iter. Total: 0.1624 s/iter. ETA=0:00:21
[11/09 14:51:46] d2.evaluation.evaluator INFO: Inference done 1927/2026. Dataloading: 0.0008 s/iter. Inference: 0.0473 s/iter. Eval: 0.1144 s/iter. Total: 0.1624 s/iter. ETA=0:00:16
[11/09 14:51:51] d2.evaluation.evaluator INFO: Inference done 1955/2026. Dataloading: 0.0008 s/iter. Inference: 0.0472 s/iter. Eval: 0.1147 s/iter. Total: 0.1627 s/iter. ETA=0:00:11
[11/09 14:51:56] d2.evaluation.evaluator INFO: Inference done 1985/2026. Dataloading: 0.0008 s/iter. Inference: 0.0473 s/iter. Eval: 0.1147 s/iter. Total: 0.1628 s/iter. ETA=0:00:06
[11/09 14:52:01] d2.evaluation.evaluator INFO: Inference done 2014/2026. Dataloading: 0.0008 s/iter. Inference: 0.0473 s/iter. Eval: 0.1149 s/iter. Total: 0.1630 s/iter. ETA=0:00:01
[11/09 14:52:06] d2.evaluation.evaluator INFO: Total inference time: 0:05:32.341373 (0.164444 s / iter per device, on 1 devices)
[11/09 14:52:06] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:35 (0.047263 s / iter per device, on 1 devices)
[11/09 14:52:07] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/09 14:52:07] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[11/09 14:52:07] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/09 14:52:08] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/09 14:52:08] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.35 seconds.
[11/09 14:52:08] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/09 14:52:08] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.12 seconds.
[11/09 14:52:08] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 38.083 | 62.571 | 37.132 | 2.212 | 14.990 | 44.009 |
[11/09 14:52:11] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/09 14:52:12] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 1.37 seconds.
[11/09 14:52:12] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/09 14:52:12] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.12 seconds.
[11/09 14:52:12] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 37.997 | 64.794 | 37.441 | 2.134 | 17.556 | 43.418 |
[11/09 14:52:12] d2.engine.defaults INFO: Evaluation results for my_data_test_coco_cod_style in csv format:
[11/09 14:52:12] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/09 14:52:12] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/09 14:52:12] d2.evaluation.testing INFO: copypaste: 38.0829,62.5711,37.1319,2.2118,14.9897,44.0091
[11/09 14:52:12] d2.evaluation.testing INFO: copypaste: Task: segm
[11/09 14:52:12] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/09 14:52:12] d2.evaluation.testing INFO: copypaste: 37.9974,64.7938,37.4408,2.1339,17.5562,43.4185
[11/09 14:52:13] d2.data.datasets.coco INFO: Loaded 4121 images in COCO format from /media/pjl307/data/experiment/datasets/CIS/annotations/nc4k_test.json
[11/09 14:52:13] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| foreground | 4580         |
|            |              |[0m
[11/09 14:52:13] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/09 14:52:13] d2.data.common INFO: Serializing 4121 elements to byte tensors and concatenating them all ...
[11/09 14:52:13] d2.data.common INFO: Serialized dataset takes 7.74 MiB
[11/09 14:52:13] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/09 14:52:13] d2.evaluation.evaluator INFO: Start inference on 4121 batches
[11/09 14:52:15] d2.evaluation.evaluator INFO: Inference done 11/4121. Dataloading: 0.0006 s/iter. Inference: 0.0433 s/iter. Eval: 0.0506 s/iter. Total: 0.0945 s/iter. ETA=0:06:28
[11/09 14:52:20] d2.evaluation.evaluator INFO: Inference done 62/4121. Dataloading: 0.0008 s/iter. Inference: 0.0443 s/iter. Eval: 0.0536 s/iter. Total: 0.0987 s/iter. ETA=0:06:40
[11/09 14:52:25] d2.evaluation.evaluator INFO: Inference done 115/4121. Dataloading: 0.0008 s/iter. Inference: 0.0444 s/iter. Eval: 0.0520 s/iter. Total: 0.0972 s/iter. ETA=0:06:29
[11/09 14:52:30] d2.evaluation.evaluator INFO: Inference done 171/4121. Dataloading: 0.0008 s/iter. Inference: 0.0445 s/iter. Eval: 0.0496 s/iter. Total: 0.0949 s/iter. ETA=0:06:14
[11/09 14:52:35] d2.evaluation.evaluator INFO: Inference done 225/4121. Dataloading: 0.0008 s/iter. Inference: 0.0443 s/iter. Eval: 0.0494 s/iter. Total: 0.0945 s/iter. ETA=0:06:08
[11/09 14:52:40] d2.evaluation.evaluator INFO: Inference done 279/4121. Dataloading: 0.0008 s/iter. Inference: 0.0444 s/iter. Eval: 0.0489 s/iter. Total: 0.0941 s/iter. ETA=0:06:01
[11/09 14:52:45] d2.evaluation.evaluator INFO: Inference done 330/4121. Dataloading: 0.0008 s/iter. Inference: 0.0444 s/iter. Eval: 0.0497 s/iter. Total: 0.0949 s/iter. ETA=0:05:59
[11/09 14:52:50] d2.evaluation.evaluator INFO: Inference done 387/4121. Dataloading: 0.0008 s/iter. Inference: 0.0445 s/iter. Eval: 0.0487 s/iter. Total: 0.0939 s/iter. ETA=0:05:50
[11/09 14:52:55] d2.evaluation.evaluator INFO: Inference done 440/4121. Dataloading: 0.0008 s/iter. Inference: 0.0448 s/iter. Eval: 0.0484 s/iter. Total: 0.0940 s/iter. ETA=0:05:46
[11/09 14:53:00] d2.evaluation.evaluator INFO: Inference done 495/4121. Dataloading: 0.0008 s/iter. Inference: 0.0449 s/iter. Eval: 0.0481 s/iter. Total: 0.0938 s/iter. ETA=0:05:40
[11/09 14:53:05] d2.evaluation.evaluator INFO: Inference done 552/4121. Dataloading: 0.0008 s/iter. Inference: 0.0450 s/iter. Eval: 0.0475 s/iter. Total: 0.0933 s/iter. ETA=0:05:32
[11/09 14:53:10] d2.evaluation.evaluator INFO: Inference done 608/4121. Dataloading: 0.0008 s/iter. Inference: 0.0449 s/iter. Eval: 0.0473 s/iter. Total: 0.0930 s/iter. ETA=0:05:26
[11/09 14:53:15] d2.evaluation.evaluator INFO: Inference done 665/4121. Dataloading: 0.0008 s/iter. Inference: 0.0449 s/iter. Eval: 0.0470 s/iter. Total: 0.0927 s/iter. ETA=0:05:20
[11/09 14:53:21] d2.evaluation.evaluator INFO: Inference done 720/4121. Dataloading: 0.0008 s/iter. Inference: 0.0449 s/iter. Eval: 0.0470 s/iter. Total: 0.0926 s/iter. ETA=0:05:15
[11/09 14:53:26] d2.evaluation.evaluator INFO: Inference done 772/4121. Dataloading: 0.0008 s/iter. Inference: 0.0449 s/iter. Eval: 0.0473 s/iter. Total: 0.0930 s/iter. ETA=0:05:11
[11/09 14:53:31] d2.evaluation.evaluator INFO: Inference done 826/4121. Dataloading: 0.0008 s/iter. Inference: 0.0448 s/iter. Eval: 0.0474 s/iter. Total: 0.0930 s/iter. ETA=0:05:06
[11/09 14:53:36] d2.evaluation.evaluator INFO: Inference done 884/4121. Dataloading: 0.0008 s/iter. Inference: 0.0448 s/iter. Eval: 0.0469 s/iter. Total: 0.0926 s/iter. ETA=0:04:59
[11/09 14:53:41] d2.evaluation.evaluator INFO: Inference done 942/4121. Dataloading: 0.0008 s/iter. Inference: 0.0449 s/iter. Eval: 0.0465 s/iter. Total: 0.0922 s/iter. ETA=0:04:53
[11/09 14:53:46] d2.evaluation.evaluator INFO: Inference done 993/4121. Dataloading: 0.0008 s/iter. Inference: 0.0449 s/iter. Eval: 0.0468 s/iter. Total: 0.0926 s/iter. ETA=0:04:49
[11/09 14:53:51] d2.evaluation.evaluator INFO: Inference done 1048/4121. Dataloading: 0.0008 s/iter. Inference: 0.0449 s/iter. Eval: 0.0468 s/iter. Total: 0.0925 s/iter. ETA=0:04:44
[11/09 14:53:56] d2.evaluation.evaluator INFO: Inference done 1105/4121. Dataloading: 0.0008 s/iter. Inference: 0.0449 s/iter. Eval: 0.0466 s/iter. Total: 0.0923 s/iter. ETA=0:04:38
[11/09 14:54:01] d2.evaluation.evaluator INFO: Inference done 1162/4121. Dataloading: 0.0008 s/iter. Inference: 0.0449 s/iter. Eval: 0.0465 s/iter. Total: 0.0921 s/iter. ETA=0:04:32
[11/09 14:54:06] d2.evaluation.evaluator INFO: Inference done 1213/4121. Dataloading: 0.0008 s/iter. Inference: 0.0449 s/iter. Eval: 0.0467 s/iter. Total: 0.0924 s/iter. ETA=0:04:28
[11/09 14:54:11] d2.evaluation.evaluator INFO: Inference done 1271/4121. Dataloading: 0.0008 s/iter. Inference: 0.0449 s/iter. Eval: 0.0465 s/iter. Total: 0.0922 s/iter. ETA=0:04:22
[11/09 14:54:16] d2.evaluation.evaluator INFO: Inference done 1327/4121. Dataloading: 0.0008 s/iter. Inference: 0.0449 s/iter. Eval: 0.0464 s/iter. Total: 0.0920 s/iter. ETA=0:04:17
[11/09 14:54:21] d2.evaluation.evaluator INFO: Inference done 1384/4121. Dataloading: 0.0008 s/iter. Inference: 0.0448 s/iter. Eval: 0.0463 s/iter. Total: 0.0919 s/iter. ETA=0:04:11
[11/09 14:54:26] d2.evaluation.evaluator INFO: Inference done 1436/4121. Dataloading: 0.0008 s/iter. Inference: 0.0448 s/iter. Eval: 0.0465 s/iter. Total: 0.0921 s/iter. ETA=0:04:07
[11/09 14:54:31] d2.evaluation.evaluator INFO: Inference done 1490/4121. Dataloading: 0.0008 s/iter. Inference: 0.0448 s/iter. Eval: 0.0466 s/iter. Total: 0.0922 s/iter. ETA=0:04:02
[11/09 14:54:36] d2.evaluation.evaluator INFO: Inference done 1547/4121. Dataloading: 0.0008 s/iter. Inference: 0.0448 s/iter. Eval: 0.0464 s/iter. Total: 0.0920 s/iter. ETA=0:03:56
[11/09 14:54:41] d2.evaluation.evaluator INFO: Inference done 1602/4121. Dataloading: 0.0008 s/iter. Inference: 0.0447 s/iter. Eval: 0.0465 s/iter. Total: 0.0920 s/iter. ETA=0:03:51
[11/09 14:54:46] d2.evaluation.evaluator INFO: Inference done 1659/4121. Dataloading: 0.0008 s/iter. Inference: 0.0447 s/iter. Eval: 0.0464 s/iter. Total: 0.0919 s/iter. ETA=0:03:46
[11/09 14:54:51] d2.evaluation.evaluator INFO: Inference done 1712/4121. Dataloading: 0.0008 s/iter. Inference: 0.0447 s/iter. Eval: 0.0465 s/iter. Total: 0.0920 s/iter. ETA=0:03:41
[11/09 14:54:56] d2.evaluation.evaluator INFO: Inference done 1769/4121. Dataloading: 0.0008 s/iter. Inference: 0.0447 s/iter. Eval: 0.0464 s/iter. Total: 0.0919 s/iter. ETA=0:03:36
[11/09 14:55:01] d2.evaluation.evaluator INFO: Inference done 1827/4121. Dataloading: 0.0008 s/iter. Inference: 0.0447 s/iter. Eval: 0.0462 s/iter. Total: 0.0918 s/iter. ETA=0:03:30
[11/09 14:55:07] d2.evaluation.evaluator INFO: Inference done 1886/4121. Dataloading: 0.0008 s/iter. Inference: 0.0447 s/iter. Eval: 0.0461 s/iter. Total: 0.0916 s/iter. ETA=0:03:24
[11/09 14:55:12] d2.evaluation.evaluator INFO: Inference done 1944/4121. Dataloading: 0.0008 s/iter. Inference: 0.0447 s/iter. Eval: 0.0459 s/iter. Total: 0.0914 s/iter. ETA=0:03:19
[11/09 14:55:17] d2.evaluation.evaluator INFO: Inference done 1999/4121. Dataloading: 0.0008 s/iter. Inference: 0.0447 s/iter. Eval: 0.0459 s/iter. Total: 0.0914 s/iter. ETA=0:03:13
[11/09 14:55:22] d2.evaluation.evaluator INFO: Inference done 2051/4121. Dataloading: 0.0008 s/iter. Inference: 0.0447 s/iter. Eval: 0.0461 s/iter. Total: 0.0916 s/iter. ETA=0:03:09
[11/09 14:55:27] d2.evaluation.evaluator INFO: Inference done 2108/4121. Dataloading: 0.0008 s/iter. Inference: 0.0447 s/iter. Eval: 0.0460 s/iter. Total: 0.0915 s/iter. ETA=0:03:04
[11/09 14:55:32] d2.evaluation.evaluator INFO: Inference done 2161/4121. Dataloading: 0.0008 s/iter. Inference: 0.0447 s/iter. Eval: 0.0460 s/iter. Total: 0.0916 s/iter. ETA=0:02:59
[11/09 14:55:37] d2.evaluation.evaluator INFO: Inference done 2217/4121. Dataloading: 0.0008 s/iter. Inference: 0.0447 s/iter. Eval: 0.0460 s/iter. Total: 0.0915 s/iter. ETA=0:02:54
[11/09 14:55:42] d2.evaluation.evaluator INFO: Inference done 2272/4121. Dataloading: 0.0008 s/iter. Inference: 0.0447 s/iter. Eval: 0.0460 s/iter. Total: 0.0915 s/iter. ETA=0:02:49
[11/09 14:55:47] d2.evaluation.evaluator INFO: Inference done 2327/4121. Dataloading: 0.0008 s/iter. Inference: 0.0447 s/iter. Eval: 0.0460 s/iter. Total: 0.0915 s/iter. ETA=0:02:44
[11/09 14:55:52] d2.evaluation.evaluator INFO: Inference done 2385/4121. Dataloading: 0.0008 s/iter. Inference: 0.0447 s/iter. Eval: 0.0459 s/iter. Total: 0.0914 s/iter. ETA=0:02:38
[11/09 14:55:57] d2.evaluation.evaluator INFO: Inference done 2442/4121. Dataloading: 0.0008 s/iter. Inference: 0.0447 s/iter. Eval: 0.0458 s/iter. Total: 0.0913 s/iter. ETA=0:02:33
[11/09 14:56:02] d2.evaluation.evaluator INFO: Inference done 2499/4121. Dataloading: 0.0007 s/iter. Inference: 0.0447 s/iter. Eval: 0.0458 s/iter. Total: 0.0913 s/iter. ETA=0:02:28
[11/09 14:56:07] d2.evaluation.evaluator INFO: Inference done 2552/4121. Dataloading: 0.0007 s/iter. Inference: 0.0447 s/iter. Eval: 0.0458 s/iter. Total: 0.0913 s/iter. ETA=0:02:23
[11/09 14:56:12] d2.evaluation.evaluator INFO: Inference done 2607/4121. Dataloading: 0.0007 s/iter. Inference: 0.0447 s/iter. Eval: 0.0458 s/iter. Total: 0.0913 s/iter. ETA=0:02:18
[11/09 14:56:17] d2.evaluation.evaluator INFO: Inference done 2666/4121. Dataloading: 0.0007 s/iter. Inference: 0.0447 s/iter. Eval: 0.0457 s/iter. Total: 0.0912 s/iter. ETA=0:02:12
[11/09 14:56:22] d2.evaluation.evaluator INFO: Inference done 2719/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0458 s/iter. Total: 0.0913 s/iter. ETA=0:02:07
[11/09 14:56:27] d2.evaluation.evaluator INFO: Inference done 2777/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0457 s/iter. Total: 0.0912 s/iter. ETA=0:02:02
[11/09 14:56:32] d2.evaluation.evaluator INFO: Inference done 2832/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0457 s/iter. Total: 0.0912 s/iter. ETA=0:01:57
[11/09 14:56:37] d2.evaluation.evaluator INFO: Inference done 2888/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0457 s/iter. Total: 0.0912 s/iter. ETA=0:01:52
[11/09 14:56:42] d2.evaluation.evaluator INFO: Inference done 2940/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0458 s/iter. Total: 0.0913 s/iter. ETA=0:01:47
[11/09 14:56:47] d2.evaluation.evaluator INFO: Inference done 2994/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0458 s/iter. Total: 0.0913 s/iter. ETA=0:01:42
[11/09 14:56:52] d2.evaluation.evaluator INFO: Inference done 3048/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0458 s/iter. Total: 0.0914 s/iter. ETA=0:01:38
[11/09 14:56:57] d2.evaluation.evaluator INFO: Inference done 3105/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0458 s/iter. Total: 0.0913 s/iter. ETA=0:01:32
[11/09 14:57:02] d2.evaluation.evaluator INFO: Inference done 3164/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0457 s/iter. Total: 0.0912 s/iter. ETA=0:01:27
[11/09 14:57:07] d2.evaluation.evaluator INFO: Inference done 3217/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0457 s/iter. Total: 0.0913 s/iter. ETA=0:01:22
[11/09 14:57:13] d2.evaluation.evaluator INFO: Inference done 3274/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0457 s/iter. Total: 0.0912 s/iter. ETA=0:01:17
[11/09 14:57:18] d2.evaluation.evaluator INFO: Inference done 3331/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0456 s/iter. Total: 0.0912 s/iter. ETA=0:01:12
[11/09 14:57:23] d2.evaluation.evaluator INFO: Inference done 3388/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0456 s/iter. Total: 0.0911 s/iter. ETA=0:01:06
[11/09 14:57:28] d2.evaluation.evaluator INFO: Inference done 3445/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0456 s/iter. Total: 0.0911 s/iter. ETA=0:01:01
[11/09 14:57:33] d2.evaluation.evaluator INFO: Inference done 3502/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0455 s/iter. Total: 0.0911 s/iter. ETA=0:00:56
[11/09 14:57:38] d2.evaluation.evaluator INFO: Inference done 3557/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0456 s/iter. Total: 0.0911 s/iter. ETA=0:00:51
[11/09 14:57:43] d2.evaluation.evaluator INFO: Inference done 3616/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0455 s/iter. Total: 0.0910 s/iter. ETA=0:00:45
[11/09 14:57:48] d2.evaluation.evaluator INFO: Inference done 3671/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0455 s/iter. Total: 0.0910 s/iter. ETA=0:00:40
[11/09 14:57:53] d2.evaluation.evaluator INFO: Inference done 3724/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0455 s/iter. Total: 0.0911 s/iter. ETA=0:00:36
[11/09 14:57:58] d2.evaluation.evaluator INFO: Inference done 3777/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0456 s/iter. Total: 0.0911 s/iter. ETA=0:00:31
[11/09 14:58:03] d2.evaluation.evaluator INFO: Inference done 3833/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0456 s/iter. Total: 0.0911 s/iter. ETA=0:00:26
[11/09 14:58:08] d2.evaluation.evaluator INFO: Inference done 3887/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0456 s/iter. Total: 0.0911 s/iter. ETA=0:00:21
[11/09 14:58:13] d2.evaluation.evaluator INFO: Inference done 3946/4121. Dataloading: 0.0007 s/iter. Inference: 0.0447 s/iter. Eval: 0.0455 s/iter. Total: 0.0910 s/iter. ETA=0:00:15
[11/09 14:58:18] d2.evaluation.evaluator INFO: Inference done 3997/4121. Dataloading: 0.0007 s/iter. Inference: 0.0447 s/iter. Eval: 0.0456 s/iter. Total: 0.0911 s/iter. ETA=0:00:11
[11/09 14:58:23] d2.evaluation.evaluator INFO: Inference done 4048/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0457 s/iter. Total: 0.0912 s/iter. ETA=0:00:06
[11/09 14:58:28] d2.evaluation.evaluator INFO: Inference done 4104/4121. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0457 s/iter. Total: 0.0912 s/iter. ETA=0:00:01
[11/09 14:58:30] d2.evaluation.evaluator INFO: Total inference time: 0:06:15.576176 (0.091248 s / iter per device, on 1 devices)
[11/09 14:58:30] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:03:04 (0.044788 s / iter per device, on 1 devices)
[11/09 14:58:31] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/09 14:58:31] d2.evaluation.coco_evaluation INFO: Saving results to ./output/inference/coco_instances_results.json
[11/09 14:58:31] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/09 14:58:33] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/09 14:58:34] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.72 seconds.
[11/09 14:58:34] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/09 14:58:34] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.26 seconds.
[11/09 14:58:34] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 41.050 | 68.163 | 39.908 | 6.996 | 15.629 | 46.136 |
[11/09 14:58:38] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *segm*
[11/09 14:58:40] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 1.96 seconds.
[11/09 14:58:40] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/09 14:58:41] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.26 seconds.
[11/09 14:58:41] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 39.411 | 66.360 | 39.581 | 0.638 | 19.637 | 43.314 |
[11/09 14:58:41] d2.engine.defaults INFO: Evaluation results for my_data_test_coco_nc4k_style in csv format:
[11/09 14:58:41] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/09 14:58:41] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/09 14:58:41] d2.evaluation.testing INFO: copypaste: 41.0503,68.1634,39.9085,6.9957,15.6286,46.1362
[11/09 14:58:41] d2.evaluation.testing INFO: copypaste: Task: segm
[11/09 14:58:41] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/09 14:58:41] d2.evaluation.testing INFO: copypaste: 39.4111,66.3601,39.5812,0.6383,19.6373,43.3143
